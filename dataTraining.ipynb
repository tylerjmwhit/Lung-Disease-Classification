{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pickle import load,dump\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Tyler/PycharmProjects/EE485_Final_Project/labeled_df.csv\")\n",
    "df = df.drop('Unnamed: 0', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['R', 'G', 'B', 'Label'], dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                       R  \\\n0      [255, 255, 255, 255, 255, 255, 255, 255, 255, ...   \n1      [255, 255, 255, 207, 140, 167, 188, 190, 167, ...   \n2      [167, 173, 152, 206, 255, 255, 255, 255, 255, ...   \n3      [255, 255, 255, 255, 255, 255, 255, 255, 255, ...   \n4      [255, 255, 255, 255, 255, 255, 255, 255, 255, ...   \n...                                                  ...   \n90898  [199, 153, 165, 191, 219, 204, 167, 177, 188, ...   \n90899  [188, 139, 124, 120, 255, 255, 255, 255, 255, ...   \n90900  [193, 200, 167, 175, 162, 183, 185, 164, 163, ...   \n90901  [163, 203, 184, 199, 255, 221, 168, 154, 176, ...   \n90902  [176, 169, 185, 167, 221, 245, 175, 161, 165, ...   \n\n                                                       G  \\\n0      [255, 255, 255, 255, 255, 255, 255, 255, 255, ...   \n1      [255, 255, 160, 0, 0, 0, 0, 0, 0, 0, 0, 0, 141...   \n2      [0, 0, 0, 0, 141, 255, 255, 255, 255, 255, 255...   \n3      [255, 255, 255, 255, 255, 255, 255, 255, 255, ...   \n4      [255, 255, 255, 255, 255, 255, 255, 255, 255, ...   \n...                                                  ...   \n90898  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 255, 2...   \n90899  [0, 0, 0, 0, 9, 255, 255, 255, 255, 255, 255, ...   \n90900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 159, 0, 0...   \n90901  [0, 0, 0, 0, 159, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n90902  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35,...   \n\n                                                       B         Label  \n0      [137, 145, 184, 127, 167, 175, 149, 124, 196, ...  micronodules  \n1      [196, 94, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 87,...  micronodules  \n2      [0, 0, 0, 0, 0, 87, 31, 16, 75, 180, 255, 255,...  micronodules  \n3      [142, 55, 139, 175, 153, 129, 100, 126, 159, 1...  micronodules  \n4      [159, 159, 161, 201, 210, 189, 205, 238, 191, ...  micronodules  \n...                                                  ...           ...  \n90898  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 1...     emphysema  \n90899  [0, 0, 0, 0, 0, 255, 173, 180, 150, 100, 191, ...     emphysema  \n90900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     emphysema  \n90901  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     emphysema  \n90902  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     emphysema  \n\n[90903 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R</th>\n      <th>G</th>\n      <th>B</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n      <td>[137, 145, 184, 127, 167, 175, 149, 124, 196, ...</td>\n      <td>micronodules</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[255, 255, 255, 207, 140, 167, 188, 190, 167, ...</td>\n      <td>[255, 255, 160, 0, 0, 0, 0, 0, 0, 0, 0, 0, 141...</td>\n      <td>[196, 94, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 87,...</td>\n      <td>micronodules</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[167, 173, 152, 206, 255, 255, 255, 255, 255, ...</td>\n      <td>[0, 0, 0, 0, 141, 255, 255, 255, 255, 255, 255...</td>\n      <td>[0, 0, 0, 0, 0, 87, 31, 16, 75, 180, 255, 255,...</td>\n      <td>micronodules</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n      <td>[142, 55, 139, 175, 153, 129, 100, 126, 159, 1...</td>\n      <td>micronodules</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n      <td>[159, 159, 161, 201, 210, 189, 205, 238, 191, ...</td>\n      <td>micronodules</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90898</th>\n      <td>[199, 153, 165, 191, 219, 204, 167, 177, 188, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 255, 2...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 1...</td>\n      <td>emphysema</td>\n    </tr>\n    <tr>\n      <th>90899</th>\n      <td>[188, 139, 124, 120, 255, 255, 255, 255, 255, ...</td>\n      <td>[0, 0, 0, 0, 9, 255, 255, 255, 255, 255, 255, ...</td>\n      <td>[0, 0, 0, 0, 0, 255, 173, 180, 150, 100, 191, ...</td>\n      <td>emphysema</td>\n    </tr>\n    <tr>\n      <th>90900</th>\n      <td>[193, 200, 167, 175, 162, 183, 185, 164, 163, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 159, 0, 0...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>emphysema</td>\n    </tr>\n    <tr>\n      <th>90901</th>\n      <td>[163, 203, 184, 199, 255, 221, 168, 154, 176, ...</td>\n      <td>[0, 0, 0, 0, 159, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>emphysema</td>\n    </tr>\n    <tr>\n      <th>90902</th>\n      <td>[176, 169, 185, 167, 221, 245, 175, 161, 165, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>emphysema</td>\n    </tr>\n  </tbody>\n</table>\n<p>90903 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def makeIMG(n,string):\n",
    "  Image1 = df[string].values[n]\n",
    "  Image1 = Image1.replace('[','')\n",
    "  Image1 = Image1.replace(']','')\n",
    "  Image1 = Image1.split(\",\")\n",
    "  Image1 = np.array(Image1).astype(float)\n",
    "  Image1 = Image1.reshape(32,32)\n",
    "  Image1 = Image1/255\n",
    "  return Image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]\n",
      " ...\n",
      " [0.78823529 0.75686275 0.97647059 ... 0.57254902 0.59607843 0.6       ]\n",
      " [0.95686275 0.81960784 0.76862745 ... 0.50196078 0.50196078 0.50588235]\n",
      " [0.66666667 0.70980392 0.53333333 ... 0.6627451  0.70196078 0.68627451]]\n"
     ]
    }
   ],
   "source": [
    "Image1 = df['R'].values[0]\n",
    "Image1 = Image1.replace('[','')\n",
    "#print(Image1)\n",
    "Image1 = Image1.replace(']','')\n",
    "Image1 = Image1.split(\",\")\n",
    "Image1 = np.array(Image1).astype(int)\n",
    "Image1 = Image1.reshape(32,32)\n",
    "Image1 = Image1/255\n",
    "print(Image1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_rgb = []\n",
    "for i in range(len(df)):\n",
    "  images_rgb.append(np.dstack((makeIMG(i,'R'),makeIMG(i,'G'),makeIMG(i,'B'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'micronodules'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images_rgb[7314])\n",
    "df['Label'][7314]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['emphysema', 'fibrosis', 'ground_glass', 'healthy', 'micronodules'],\n       dtype=object)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(targets.reshape(-1,1))\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#saving my encoder\n",
    "##dump(enc,open('enc.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = enc.transform(targets.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_rgb_shuffle, y_train_shuffle = shuffle(images_rgb, y_train, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(90903, 5)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(images_rgb_shuffle).shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x1, valid_x, train_y1, valid_y = train_test_split(np.array(images_rgb_shuffle), y_train_shuffle, test_size= .5, stratify=y_train_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                115250    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,897\n",
      "Trainable params: 134,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core.flatten import Flatten\n",
    "from keras import layers, models\n",
    "model_int = models.Sequential([\n",
    "    layers.InputLayer(input_shape=[32,32,3]),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "\n",
    "\n",
    "\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "model_int.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers import *\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor = 'val_loss',patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience=3, min_lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# early_stopping_monitor = EarlyStopping(monitor = 'loss',patience=5, restore_best_weights=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor = 0.3, patience=3, min_lr=0.000001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1421/1421 [==============================] - 7s 3ms/step - loss: 0.6775 - val_loss: 0.5086 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.4557 - val_loss: 0.3959 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.3831 - val_loss: 0.3731 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.3332 - val_loss: 0.3894 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.2995 - val_loss: 0.3443 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.2694 - val_loss: 0.3079 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.2431 - val_loss: 0.3427 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.2203 - val_loss: 0.2781 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.1977 - val_loss: 0.3052 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.1756 - val_loss: 0.3013 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.1569 - val_loss: 0.3617 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0921 - val_loss: 0.2625 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0837 - val_loss: 0.2615 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0758 - val_loss: 0.2680 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0701 - val_loss: 0.2742 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0649 - val_loss: 0.2781 - lr: 2.0000e-04\n",
      "Epoch 17/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0535 - val_loss: 0.2847 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0514 - val_loss: 0.2926 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0481 - val_loss: 0.2830 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0459 - val_loss: 0.2921 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0433 - val_loss: 0.2876 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0416 - val_loss: 0.3026 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1421/1421 [==============================] - 5s 3ms/step - loss: 0.0386 - val_loss: 0.2936 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model_int.compile(loss='categorical_crossentropy',optimizer='Adam')\n",
    "history1 = model_int.fit(train_x1,train_y1, epochs = 50, shuffle=True, callbacks=[early_stopping_monitor,reduce_lr], validation_data=(valid_x,valid_y), validation_freq=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0629\n",
      "Epoch 2/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0519\n",
      "Epoch 3/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0513\n",
      "Epoch 4/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0452\n",
      "Epoch 5/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0432\n",
      "Epoch 6/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0441\n",
      "Epoch 7/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0359\n",
      "Epoch 8/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0419\n",
      "Epoch 9/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0344\n",
      "Epoch 10/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0357\n",
      "Epoch 11/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0355\n",
      "Epoch 12/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0301\n",
      "Epoch 13/20\n",
      "1421/1421 [==============================] - 3s 2ms/step - loss: 0.0319\n",
      "Epoch 14/20\n",
      " 673/1421 [=============>................] - ETA: 1s - loss: 0.0237"
     ]
    }
   ],
   "source": [
    "model_int.compile(loss='categorical_crossentropy',optimizer='Adam')\n",
    "history1 = model_int.fit(train_x1,train_y1, epochs = 20, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "preds = model_int.predict(valid_x)\n",
    "preds = enc.inverse_transform(preds)\n",
    "print(classification_report(enc.inverse_transform(valid_y),preds, digits=4))\n",
    "confusion_matrix(enc.inverse_transform(valid_y),preds)\n",
    "ConfusionMatrixDisplay.from_predictions(enc.inverse_transform(valid_y),preds, normalize='true', cmap='winter', xticks_rotation= 'vertical')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "act = 'elu'\n",
    "pad = 'same'\n",
    "convul = (3,3)\n",
    "initial = 'he_normal'\n",
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "model = models.Sequential(\n",
    "    [\n",
    "     layers.InputLayer(input_shape=[32,32,3]),\n",
    "     layers.BatchNormalization(),\n",
    "     layers.Conv2D(64, convul, padding = pad, activation=leaky_relu, kernel_initializer=initial),\n",
    "     layers.Conv2D(64, convul, padding = pad, activation=act, kernel_initializer=initial),\n",
    "     layers.AvgPool2D(pool_size=2),\n",
    "     layers.Conv2D(128, convul, padding = pad, activation=leaky_relu, kernel_initializer=initial),\n",
    "     layers.Conv2D(128, convul, padding = pad, activation=act, kernel_initializer=initial),\n",
    "     layers.AvgPool2D(pool_size=2),\n",
    "     layers.BatchNormalization(),\n",
    "     layers.Conv2D(256, convul, padding = pad, activation=leaky_relu, kernel_initializer=initial),\n",
    "     layers.Conv2D(256, convul, padding = pad, activation=act, kernel_initializer=initial),\n",
    "     layers.AvgPool2D(pool_size=2),\n",
    "     layers.BatchNormalization(),\n",
    "     layers.Flatten(),\n",
    "     layers.Dense(200, activation=leaky_relu, kernel_initializer=initial),\n",
    "     layers.Dropout(.4),\n",
    "     layers.Dense(200, activation=act, kernel_initializer=initial),\n",
    "     layers.Dropout(.4),\n",
    "     layers.BatchNormalization(),\n",
    "     layers.Dense(50, activation=leaky_relu, kernel_initializer=initial),\n",
    "     layers.Dropout(.4),\n",
    "\n",
    "\n",
    "\n",
    "     layers.Dense(5, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# act = 'elu'\n",
    "# pad = 'same'\n",
    "kernel = 3\n",
    "pad = 'same'\n",
    "initial = 'he_normal'\n",
    "opt = 'adam'\n",
    "def create_model(act = 'elu', drop = .4, filter = 64, nodes = 50, act2 = 'relu', convul_amount = 3, maxavg= True ):\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=[32,32,3]))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    for layer_amount in range(1,convul_amount):\n",
    "        model.add(Conv2D(filters = layer_amount*filter, kernel_size= kernel, padding = pad, activation=act2, kernel_initializer=initial))\n",
    "        model.add(Conv2D(filters = layer_amount*filter, kernel_size= kernel, padding = pad, activation=act, kernel_initializer=initial))\n",
    "        if maxavg:\n",
    "            model.add(AvgPool2D(pool_size=2))\n",
    "        else:\n",
    "            model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(units = 4*nodes, activation=act2, kernel_initializer=initial))\n",
    "    model.add(Dense(units = 4*nodes, activation=act, kernel_initializer=initial))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(units = nodes, activation=act2, kernel_initializer=initial))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt, metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "params = {\n",
    "    'act':['elu',leaky_relu],\n",
    "    'drop':[.3,.4],\n",
    "    'filter':[32,64],\n",
    "    'nodes':[25,50],\n",
    "    'act2':['elu','relu'],\n",
    "    'convul_amount':[3,4],\n",
    "    'maxavg':[True,False],\n",
    "    'batch_size':[8,16],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tyler\\AppData\\Local\\Temp\\ipykernel_2840\\3636745365.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,epochs = 7, verbose = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV 1/3; 1/30] START act=elu, act2=elu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 12s 6ms/step - loss: 0.6821 - accuracy: 0.7668\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.4344 - accuracy: 0.8525\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.3558 - accuracy: 0.8782\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3035 - accuracy: 0.8965\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2594 - accuracy: 0.9081\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.2135 - accuracy: 0.9252\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 10s 6ms/step - loss: 0.1831 - accuracy: 0.9356\n",
      "950/950 [==============================] - 2s 2ms/step - loss: 0.2533 - accuracy: 0.9132\n",
      "[CV 1/3; 1/30] END act=elu, act2=elu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=False, nodes=50;, score=0.913 total time= 1.2min\n",
      "[CV 2/3; 1/30] START act=elu, act2=elu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.6607 - accuracy: 0.7735\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.4334 - accuracy: 0.8547\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3565 - accuracy: 0.8729\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2985 - accuracy: 0.8964\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2533 - accuracy: 0.9107\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2091 - accuracy: 0.9269\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.1897 - accuracy: 0.9339\n",
      "950/950 [==============================] - 2s 2ms/step - loss: 0.2730 - accuracy: 0.9093\n",
      "[CV 2/3; 1/30] END act=elu, act2=elu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=False, nodes=50;, score=0.909 total time= 1.2min\n",
      "[CV 3/3; 1/30] START act=elu, act2=elu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.6715 - accuracy: 0.7703\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.4286 - accuracy: 0.8530\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.3490 - accuracy: 0.8806\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.2914 - accuracy: 0.9009\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2509 - accuracy: 0.9135\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.2096 - accuracy: 0.9268\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.1779 - accuracy: 0.9393\n",
      "950/950 [==============================] - 2s 2ms/step - loss: 0.2396 - accuracy: 0.9189\n",
      "[CV 3/3; 1/30] END act=elu, act2=elu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=False, nodes=50;, score=0.919 total time= 1.2min\n",
      "[CV 1/3; 2/30] START act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=64, maxavg=True, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 12s 6ms/step - loss: 0.7338 - accuracy: 0.7334\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.4629 - accuracy: 0.8426\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3867 - accuracy: 0.8696\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3429 - accuracy: 0.8840\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2989 - accuracy: 0.8966\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2600 - accuracy: 0.9099\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2281 - accuracy: 0.9200\n",
      "950/950 [==============================] - 3s 3ms/step - loss: 0.2521 - accuracy: 0.9253\n",
      "[CV 1/3; 2/30] END act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=64, maxavg=True, nodes=50;, score=0.925 total time= 1.3min\n",
      "[CV 2/3; 2/30] START act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=64, maxavg=True, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 11s 5ms/step - loss: 0.6731 - accuracy: 0.7626\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.4334 - accuracy: 0.8532\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3868 - accuracy: 0.8697\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3552 - accuracy: 0.8769\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2939 - accuracy: 0.9002\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3163 - accuracy: 0.8904\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.2402 - accuracy: 0.9158\n",
      "950/950 [==============================] - 3s 3ms/step - loss: 0.1952 - accuracy: 0.9311\n",
      "[CV 2/3; 2/30] END act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=64, maxavg=True, nodes=50;, score=0.931 total time= 1.3min\n",
      "[CV 3/3; 2/30] START act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=64, maxavg=True, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 11s 5ms/step - loss: 0.7609 - accuracy: 0.7241\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.4651 - accuracy: 0.8397\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.3944 - accuracy: 0.8673\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3309 - accuracy: 0.8879\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2846 - accuracy: 0.9045\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.2432 - accuracy: 0.9155\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2063 - accuracy: 0.9291\n",
      "950/950 [==============================] - 3s 2ms/step - loss: 0.2542 - accuracy: 0.9154\n",
      "[CV 3/3; 2/30] END act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=64, maxavg=True, nodes=50;, score=0.915 total time= 1.2min\n",
      "[CV 1/3; 3/30] START act=elu, act2=elu, batch_size=8, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "3797/3797 [==============================] - 21s 5ms/step - loss: 0.8078 - accuracy: 0.7245\n",
      "Epoch 2/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.5066 - accuracy: 0.8305\n",
      "Epoch 3/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.4069 - accuracy: 0.8643\n",
      "Epoch 4/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.3485 - accuracy: 0.8820\n",
      "Epoch 5/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.2993 - accuracy: 0.8991\n",
      "Epoch 6/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.2576 - accuracy: 0.9135\n",
      "Epoch 7/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.2243 - accuracy: 0.9264\n",
      "1899/1899 [==============================] - 4s 2ms/step - loss: 0.2128 - accuracy: 0.9260\n",
      "[CV 1/3; 3/30] END act=elu, act2=elu, batch_size=8, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50;, score=0.926 total time= 2.4min\n",
      "[CV 2/3; 3/30] START act=elu, act2=elu, batch_size=8, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "3797/3797 [==============================] - 21s 5ms/step - loss: 0.8069 - accuracy: 0.7242\n",
      "Epoch 2/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.4991 - accuracy: 0.8309\n",
      "Epoch 3/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.4109 - accuracy: 0.8608\n",
      "Epoch 4/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.3425 - accuracy: 0.8847\n",
      "Epoch 5/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.2949 - accuracy: 0.9019\n",
      "Epoch 6/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.2547 - accuracy: 0.9145\n",
      "Epoch 7/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.2229 - accuracy: 0.9258\n",
      "1899/1899 [==============================] - 5s 2ms/step - loss: 0.2906 - accuracy: 0.9063\n",
      "[CV 2/3; 3/30] END act=elu, act2=elu, batch_size=8, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50;, score=0.906 total time= 2.4min\n",
      "[CV 3/3; 3/30] START act=elu, act2=elu, batch_size=8, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "3797/3797 [==============================] - 21s 5ms/step - loss: 0.7863 - accuracy: 0.7332\n",
      "Epoch 2/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.4890 - accuracy: 0.8338\n",
      "Epoch 3/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.4164 - accuracy: 0.8648\n",
      "Epoch 4/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.3562 - accuracy: 0.8818\n",
      "Epoch 5/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.3049 - accuracy: 0.8967\n",
      "Epoch 6/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.2668 - accuracy: 0.9116\n",
      "Epoch 7/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.2336 - accuracy: 0.9232\n",
      "1899/1899 [==============================] - 4s 2ms/step - loss: 0.1574 - accuracy: 0.9454\n",
      "[CV 3/3; 3/30] END act=elu, act2=elu, batch_size=8, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50;, score=0.945 total time= 2.4min\n",
      "[CV 1/3; 4/30] START act=<keras.layers.advanced_activations.LeakyReLU object at 0x00000181E98FE0A0>, act2=elu, batch_size=16, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 11s 5ms/step - loss: 0.7032 - accuracy: 0.7690\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.4144 - accuracy: 0.8620\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.3448 - accuracy: 0.8825\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2829 - accuracy: 0.9009\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2367 - accuracy: 0.9179\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.1962 - accuracy: 0.9323\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.1693 - accuracy: 0.9418\n",
      "950/950 [==============================] - 2s 2ms/step - loss: 0.1630 - accuracy: 0.9416\n",
      "[CV 1/3; 4/30] END act=<keras.layers.advanced_activations.LeakyReLU object at 0x00000181E98FE0A0>, act2=elu, batch_size=16, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50;, score=0.942 total time= 1.2min\n",
      "[CV 2/3; 4/30] START act=<keras.layers.advanced_activations.LeakyReLU object at 0x00000181E98FE0A0>, act2=elu, batch_size=16, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.6869 - accuracy: 0.7696\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.4000 - accuracy: 0.8650\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3377 - accuracy: 0.8844\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2800 - accuracy: 0.9030\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2361 - accuracy: 0.9168\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.1973 - accuracy: 0.9336\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.1695 - accuracy: 0.9428\n",
      "950/950 [==============================] - 2s 2ms/step - loss: 0.1849 - accuracy: 0.9342\n",
      "[CV 2/3; 4/30] END act=<keras.layers.advanced_activations.LeakyReLU object at 0x00000181E98FE0A0>, act2=elu, batch_size=16, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50;, score=0.934 total time= 1.2min\n",
      "[CV 3/3; 4/30] START act=<keras.layers.advanced_activations.LeakyReLU object at 0x00000181E98FE0A0>, act2=elu, batch_size=16, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.6899 - accuracy: 0.7702\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.4098 - accuracy: 0.8634\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3357 - accuracy: 0.8851\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.2843 - accuracy: 0.9023\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.2374 - accuracy: 0.9186\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.1980 - accuracy: 0.9310\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.1587 - accuracy: 0.9459\n",
      "950/950 [==============================] - 2s 2ms/step - loss: 0.3548 - accuracy: 0.8884\n",
      "[CV 3/3; 4/30] END act=<keras.layers.advanced_activations.LeakyReLU object at 0x00000181E98FE0A0>, act2=elu, batch_size=16, convul_amount=3, drop=0.4, filter=64, maxavg=False, nodes=50;, score=0.888 total time= 1.2min\n",
      "[CV 1/3; 5/30] START act=relu, act2=relu, batch_size=8, convul_amount=3, drop=0.4, filter=32, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.8318 - accuracy: 0.7035\n",
      "Epoch 2/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.5615 - accuracy: 0.8087\n",
      "Epoch 3/7\n",
      "3797/3797 [==============================] - 18s 5ms/step - loss: 0.4697 - accuracy: 0.8449\n",
      "Epoch 4/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.4486 - accuracy: 0.8514\n",
      "Epoch 5/7\n",
      "3797/3797 [==============================] - 18s 5ms/step - loss: 0.3830 - accuracy: 0.8731\n",
      "Epoch 6/7\n",
      "3797/3797 [==============================] - 18s 5ms/step - loss: 0.3436 - accuracy: 0.8878\n",
      "Epoch 7/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.3282 - accuracy: 0.8910\n",
      "1899/1899 [==============================] - 4s 2ms/step - loss: 0.6066 - accuracy: 0.8122\n",
      "[CV 1/3; 5/30] END act=relu, act2=relu, batch_size=8, convul_amount=3, drop=0.4, filter=32, maxavg=False, nodes=50;, score=0.812 total time= 2.2min\n",
      "[CV 2/3; 5/30] START act=relu, act2=relu, batch_size=8, convul_amount=3, drop=0.4, filter=32, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "3797/3797 [==============================] - 20s 5ms/step - loss: 0.8624 - accuracy: 0.6940\n",
      "Epoch 2/7\n",
      "3797/3797 [==============================] - 18s 5ms/step - loss: 0.5879 - accuracy: 0.7987\n",
      "Epoch 3/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.4953 - accuracy: 0.8358\n",
      "Epoch 4/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.4285 - accuracy: 0.8585\n",
      "Epoch 5/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.3889 - accuracy: 0.8721\n",
      "Epoch 6/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.3655 - accuracy: 0.8773\n",
      "Epoch 7/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.3183 - accuracy: 0.8953\n",
      "1899/1899 [==============================] - 4s 2ms/step - loss: 0.2485 - accuracy: 0.9119\n",
      "[CV 2/3; 5/30] END act=relu, act2=relu, batch_size=8, convul_amount=3, drop=0.4, filter=32, maxavg=False, nodes=50;, score=0.912 total time= 2.3min\n",
      "[CV 3/3; 5/30] START act=relu, act2=relu, batch_size=8, convul_amount=3, drop=0.4, filter=32, maxavg=False, nodes=50\n",
      "Epoch 1/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.8227 - accuracy: 0.7066\n",
      "Epoch 2/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.5492 - accuracy: 0.8170\n",
      "Epoch 3/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.4664 - accuracy: 0.8466\n",
      "Epoch 4/7\n",
      "3797/3797 [==============================] - 18s 5ms/step - loss: 0.4139 - accuracy: 0.8651\n",
      "Epoch 5/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.3675 - accuracy: 0.8787\n",
      "Epoch 6/7\n",
      "3797/3797 [==============================] - 19s 5ms/step - loss: 0.3343 - accuracy: 0.8896\n",
      "Epoch 7/7\n",
      "3797/3797 [==============================] - 18s 5ms/step - loss: 0.3259 - accuracy: 0.8933\n",
      "1899/1899 [==============================] - 4s 2ms/step - loss: 0.2563 - accuracy: 0.9114\n",
      "[CV 3/3; 5/30] END act=relu, act2=relu, batch_size=8, convul_amount=3, drop=0.4, filter=32, maxavg=False, nodes=50;, score=0.911 total time= 2.2min\n",
      "[CV 1/3; 6/30] START act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=True, nodes=25\n",
      "Epoch 1/7\n",
      "1899/1899 [==============================] - 11s 5ms/step - loss: 0.7616 - accuracy: 0.7248\n",
      "Epoch 2/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.5001 - accuracy: 0.8342\n",
      "Epoch 3/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.4199 - accuracy: 0.8614\n",
      "Epoch 4/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.3739 - accuracy: 0.8782\n",
      "Epoch 5/7\n",
      "1899/1899 [==============================] - 9s 5ms/step - loss: 0.3392 - accuracy: 0.8883\n",
      "Epoch 6/7\n",
      "1899/1899 [==============================] - 10s 5ms/step - loss: 0.3021 - accuracy: 0.9016\n",
      "Epoch 7/7\n",
      "1899/1899 [==============================] - 11s 6ms/step - loss: 0.2740 - accuracy: 0.9073\n",
      "950/950 [==============================] - 3s 3ms/step - loss: 0.2235 - accuracy: 0.9190\n",
      "[CV 1/3; 6/30] END act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=True, nodes=25;, score=0.919 total time= 1.2min\n",
      "[CV 2/3; 6/30] START act=relu, act2=relu, batch_size=16, convul_amount=3, drop=0.3, filter=32, maxavg=True, nodes=25\n",
      "Epoch 1/7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = KerasClassifier(build_fn = create_model,epochs = 7, verbose = 1)\n",
    "grid = RandomizedSearchCV(estimator= model,param_distributions=params, n_iter=30, cv=3, verbose=10)\n",
    "grid_results = grid.fit(train_x1,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.907937 using {'nodes': 50, 'maxavg': True, 'filter': 64, 'drop': 0.4, 'convul_amount': 3, 'batch_size': 16, 'act2': 'elu', 'act': 'elu'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_results.best_score_, grid_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "    nodes  maxavg  filter  drop  convul_amount  batch_size  act2  \\\n0      50    True      64   0.4              3          16   elu   \n12     25   False      32   0.4              4           8  relu   \n15     50   False      64   0.3              3          16  relu   \n14     50    True      32   0.4              3           8   elu   \n13     50   False      32   0.4              3           8   elu   \n4      25   False      64   0.4              3          16  relu   \n1      25   False      32   0.3              4           8  relu   \n11     25   False      32   0.4              4          16  relu   \n18     50    True      32   0.3              4           8   elu   \n7      25    True      32   0.3              3           8  relu   \n5      50   False      32   0.3              3           8   elu   \n8      25    True      64   0.3              3          16   elu   \n3      50    True      32   0.3              3          16  relu   \n6      50   False      64   0.3              3           8  relu   \n9      50    True      32   0.4              3          16  relu   \n17     50    True      32   0.4              3          16   elu   \n16     25   False      64   0.4              4           8  relu   \n2      25   False      32   0.3              4          16  relu   \n19     50   False      32   0.3              4          16  relu   \n10     25    True      32   0.4              4          16  relu   \n\n                                                  act  mean_test_score  \n0                                                 elu         0.907937  \n12                                                elu         0.903416  \n15  <keras.layers.advanced_activations.LeakyReLU o...         0.899355  \n14                                                elu         0.894986  \n13  <keras.layers.advanced_activations.LeakyReLU o...         0.894262  \n4   <keras.layers.advanced_activations.LeakyReLU o...         0.892989  \n1                                                relu         0.889872  \n11  <keras.layers.advanced_activations.LeakyReLU o...         0.888686  \n18                                               relu         0.888050  \n7                                                 elu         0.884933  \n5   <keras.layers.advanced_activations.LeakyReLU o...         0.884691  \n8   <keras.layers.advanced_activations.LeakyReLU o...         0.884033  \n3                                                 elu         0.876987  \n6                                                relu         0.873804  \n9                                                 elu         0.873189  \n17                                               relu         0.872509  \n16                                                elu         0.856748  \n2                                                 elu         0.851370  \n19                                                elu         0.848801  \n10  <keras.layers.advanced_activations.LeakyReLU o...         0.844762  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nodes</th>\n      <th>maxavg</th>\n      <th>filter</th>\n      <th>drop</th>\n      <th>convul_amount</th>\n      <th>batch_size</th>\n      <th>act2</th>\n      <th>act</th>\n      <th>mean_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>True</td>\n      <td>64</td>\n      <td>0.4</td>\n      <td>3</td>\n      <td>16</td>\n      <td>elu</td>\n      <td>elu</td>\n      <td>0.907937</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>25</td>\n      <td>False</td>\n      <td>32</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>8</td>\n      <td>relu</td>\n      <td>elu</td>\n      <td>0.903416</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>50</td>\n      <td>False</td>\n      <td>64</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>&lt;keras.layers.advanced_activations.LeakyReLU o...</td>\n      <td>0.899355</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>50</td>\n      <td>True</td>\n      <td>32</td>\n      <td>0.4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>elu</td>\n      <td>elu</td>\n      <td>0.894986</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>50</td>\n      <td>False</td>\n      <td>32</td>\n      <td>0.4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>elu</td>\n      <td>&lt;keras.layers.advanced_activations.LeakyReLU o...</td>\n      <td>0.894262</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>False</td>\n      <td>64</td>\n      <td>0.4</td>\n      <td>3</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>&lt;keras.layers.advanced_activations.LeakyReLU o...</td>\n      <td>0.892989</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>False</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>4</td>\n      <td>8</td>\n      <td>relu</td>\n      <td>relu</td>\n      <td>0.889872</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>25</td>\n      <td>False</td>\n      <td>32</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>&lt;keras.layers.advanced_activations.LeakyReLU o...</td>\n      <td>0.888686</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>50</td>\n      <td>True</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>4</td>\n      <td>8</td>\n      <td>elu</td>\n      <td>relu</td>\n      <td>0.888050</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>25</td>\n      <td>True</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>relu</td>\n      <td>elu</td>\n      <td>0.884933</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50</td>\n      <td>False</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>elu</td>\n      <td>&lt;keras.layers.advanced_activations.LeakyReLU o...</td>\n      <td>0.884691</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>25</td>\n      <td>True</td>\n      <td>64</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>16</td>\n      <td>elu</td>\n      <td>&lt;keras.layers.advanced_activations.LeakyReLU o...</td>\n      <td>0.884033</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>True</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>elu</td>\n      <td>0.876987</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>50</td>\n      <td>False</td>\n      <td>64</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>relu</td>\n      <td>relu</td>\n      <td>0.873804</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>50</td>\n      <td>True</td>\n      <td>32</td>\n      <td>0.4</td>\n      <td>3</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>elu</td>\n      <td>0.873189</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>50</td>\n      <td>True</td>\n      <td>32</td>\n      <td>0.4</td>\n      <td>3</td>\n      <td>16</td>\n      <td>elu</td>\n      <td>relu</td>\n      <td>0.872509</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>25</td>\n      <td>False</td>\n      <td>64</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>8</td>\n      <td>relu</td>\n      <td>elu</td>\n      <td>0.856748</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25</td>\n      <td>False</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>4</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>elu</td>\n      <td>0.851370</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>50</td>\n      <td>False</td>\n      <td>32</td>\n      <td>0.3</td>\n      <td>4</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>elu</td>\n      <td>0.848801</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>25</td>\n      <td>True</td>\n      <td>32</td>\n      <td>0.4</td>\n      <td>4</td>\n      <td>16</td>\n      <td>relu</td>\n      <td>&lt;keras.layers.advanced_activations.LeakyReLU o...</td>\n      <td>0.844762</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_results.cv_results_['params'])\n",
    "results['mean_test_score'] = grid_results.cv_results_['mean_test_score']\n",
    "results.sort_values(by=['mean_test_score'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results.to_csv('out.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.6930 - val_loss: 0.4829 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.4369 - val_loss: 0.4386 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.3546 - val_loss: 0.2335 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.3058 - val_loss: 0.2096 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2841/2841 [==============================] - 25s 9ms/step - loss: 0.2544 - val_loss: 0.1763 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.2193 - val_loss: 0.2810 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.1826 - val_loss: 0.1312 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2841/2841 [==============================] - 24s 9ms/step - loss: 0.1586 - val_loss: 0.2738 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2841/2841 [==============================] - 25s 9ms/step - loss: 0.1494 - val_loss: 0.1380 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.1245 - val_loss: 0.0938 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.1136 - val_loss: 0.1261 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.1080 - val_loss: 0.0860 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0983 - val_loss: 0.0751 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0919 - val_loss: 0.1003 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0746 - val_loss: 0.0673 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0794 - val_loss: 0.0866 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0669 - val_loss: 0.0645 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.0766 - val_loss: 0.0874 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.0761 - val_loss: 0.0529 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0676 - val_loss: 0.0749 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0659 - val_loss: 0.0756 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2841/2841 [==============================] - 24s 9ms/step - loss: 0.0729 - val_loss: 0.0603 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0283 - val_loss: 0.0330 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0205 - val_loss: 0.0297 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.0161 - val_loss: 0.0309 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.0178 - val_loss: 0.0280 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0125 - val_loss: 0.0313 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.0140 - val_loss: 0.0297 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.0124 - val_loss: 0.0295 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.0090 - val_loss: 0.0265 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0078 - val_loss: 0.0286 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.0091 - val_loss: 0.0260 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.0088 - val_loss: 0.0274 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.0080 - val_loss: 0.0277 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0071 - val_loss: 0.0253 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0076 - val_loss: 0.0259 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.0078 - val_loss: 0.0286 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "2841/2841 [==============================] - 24s 8ms/step - loss: 0.0075 - val_loss: 0.0260 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0074 - val_loss: 0.0278 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "2841/2841 [==============================] - 22s 8ms/step - loss: 0.0065 - val_loss: 0.0260 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0067 - val_loss: 0.0271 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "2841/2841 [==============================] - 24s 9ms/step - loss: 0.0058 - val_loss: 0.0263 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0061 - val_loss: 0.0270 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0064 - val_loss: 0.0270 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "2841/2841 [==============================] - 23s 8ms/step - loss: 0.0051 - val_loss: 0.0274 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam')\n",
    "history2 = model.fit(train_x1,train_y1, epochs = 50, shuffle=True,callbacks=[early_stopping_monitor,reduce_lr], validation_data=(valid_x,valid_y) , validation_freq=1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2841/2841 [==============================] - 19s 6ms/step - loss: 0.6944 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.4375 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.3614 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2841/2841 [==============================] - 18s 6ms/step - loss: 0.3145 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2841/2841 [==============================] - 18s 6ms/step - loss: 0.2632 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.2280 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.1939 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2841/2841 [==============================] - 15s 5ms/step - loss: 0.1628 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.1460 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.1279 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.1129 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2841/2841 [==============================] - 16s 5ms/step - loss: 0.1036 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0959 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0880 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0822 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0759 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0727 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0663 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0847 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0683 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0557 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0571 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0552 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0530 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2841/2841 [==============================] - 16s 5ms/step - loss: 0.0491 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2841/2841 [==============================] - 18s 6ms/step - loss: 0.0583 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2841/2841 [==============================] - 18s 6ms/step - loss: 0.0499 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0408 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0510 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0458 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0426 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0267 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0188 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0206 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0166 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0177 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "2841/2841 [==============================] - 18s 6ms/step - loss: 0.0208 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0143 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0185 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0160 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0181 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0112 - lr: 2.5000e-04\n",
      "Epoch 43/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0087 - lr: 2.5000e-04\n",
      "Epoch 44/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0096 - lr: 2.5000e-04\n",
      "Epoch 45/50\n",
      "2841/2841 [==============================] - 17s 6ms/step - loss: 0.0074 - lr: 2.5000e-04\n",
      "Epoch 46/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0076 - lr: 2.5000e-04\n",
      "Epoch 47/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0100 - lr: 2.5000e-04\n",
      "Epoch 48/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0072 - lr: 2.5000e-04\n",
      "Epoch 49/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0067 - lr: 2.5000e-04\n",
      "Epoch 50/50\n",
      "2841/2841 [==============================] - 16s 6ms/step - loss: 0.0064 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam')\n",
    "history2 = model.fit(train_x1,train_y1, epochs = 50, shuffle=True,callbacks=[early_stopping_monitor,reduce_lr], batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   emphysema     0.9896    0.9800    0.9848      1353\n",
      "    fibrosis     0.9937    0.9921    0.9929     10793\n",
      "ground_glass     0.9887    0.9891    0.9889      7245\n",
      "     healthy     0.9945    0.9962    0.9953      9624\n",
      "micronodules     0.9957    0.9964    0.9961     16437\n",
      "\n",
      "    accuracy                         0.9937     45452\n",
      "   macro avg     0.9924    0.9908    0.9916     45452\n",
      "weighted avg     0.9937    0.9937    0.9937     45452\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "preds = model.predict(valid_x)\n",
    "preds = enc.inverse_transform(preds)\n",
    "print(classification_report(enc.inverse_transform(valid_y),preds, digits=4))\n",
    "confusion_matrix(enc.inverse_transform(valid_y),preds)\n",
    "ConfusionMatrixDisplay.from_predictions(enc.inverse_transform(valid_y),preds, normalize='true', cmap='winter', xticks_rotation= 'vertical', values_format= '.2g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_weights_9917_fall22022\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_weights_9917_fall22022\\assets\n"
     ]
    }
   ],
   "source": [
    "#saving my model\n",
    "model.save('my_weights_9917_fall22022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_28 (Bat  (None, 32, 32, 3)        12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 200)               3277000   \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 50)                10050     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,474,461\n",
      "Trainable params: 4,473,687\n",
      "Non-trainable params: 774\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Testing older models ##my best model to date\n",
    "from keras.models import load_model\n",
    "model_saved = load_model('my_weights_9981_e100.h5')\n",
    "model_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   emphysema     0.9978    0.9970    0.9974      1353\n",
      "    fibrosis     0.9969    0.9982    0.9975     10793\n",
      "ground_glass     0.9968    0.9965    0.9967      7245\n",
      "     healthy     0.9974    0.9983    0.9979      9624\n",
      "micronodules     0.9994    0.9981    0.9988     16437\n",
      "\n",
      "    accuracy                         0.9979     45452\n",
      "   macro avg     0.9977    0.9977    0.9977     45452\n",
      "weighted avg     0.9979    0.9979    0.9979     45452\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "preds = model_saved.predict(valid_x)\n",
    "preds = enc.inverse_transform(preds)\n",
    "print(classification_report(enc.inverse_transform(valid_y),preds, digits=4))\n",
    "confusion_matrix(enc.inverse_transform(valid_y),preds)\n",
    "ConfusionMatrixDisplay.from_predictions(enc.inverse_transform(valid_y),preds, normalize='true', cmap='winter', xticks_rotation= 'vertical', values_format= '.2g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   emphysema     0.9948    0.9974    0.9961      2706\n",
      "    fibrosis     0.9970    0.9979    0.9974     21586\n",
      "ground_glass     0.9967    0.9965    0.9966     14490\n",
      "     healthy     0.9976    0.9988    0.9982     19247\n",
      "micronodules     0.9993    0.9979    0.9986     32874\n",
      "\n",
      "    accuracy                         0.9978     90903\n",
      "   macro avg     0.9971    0.9977    0.9974     90903\n",
      "weighted avg     0.9978    0.9978    0.9978     90903\n",
      "\n",
      "[[ 2699     5     1     1     0]\n",
      " [   10 21540    26     5     5]\n",
      " [    1    28 14439    14     8]\n",
      " [    0     8     5 19223    11]\n",
      " [    3    24    16    26 32805]]\n"
     ]
    }
   ],
   "source": [
    "##reports for entire dataset on initial model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "preds = model_saved.predict(np.array(images_rgb))\n",
    "preds = enc.inverse_transform(preds)\n",
    "print(classification_report(enc.inverse_transform(y_train),preds, digits=4))\n",
    "print(confusion_matrix(enc.inverse_transform(y_train),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   emphysema     0.9839    0.9952    0.9895      2706\n",
      "    fibrosis     0.9967    0.9943    0.9955     21586\n",
      "ground_glass     0.9915    0.9932    0.9923     14490\n",
      "     healthy     0.9965    0.9976    0.9970     19247\n",
      "micronodules     0.9976    0.9968    0.9972     32874\n",
      "\n",
      "    accuracy                         0.9958     90903\n",
      "   macro avg     0.9932    0.9954    0.9943     90903\n",
      "weighted avg     0.9958    0.9958    0.9958     90903\n",
      "\n",
      "[[ 2693     4     5     1     3]\n",
      " [   29 21464    57    12    24]\n",
      " [    3    49 14391    19    28]\n",
      " [    9     3    10 19200    25]\n",
      " [    3    15    52    35 32769]]\n"
     ]
    }
   ],
   "source": [
    "##reports over entire dataset on tuned model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "preds = model.predict(np.array(images_rgb))\n",
    "preds = enc.inverse_transform(preds)\n",
    "print(classification_report(enc.inverse_transform(y_train),preds, digits=4))\n",
    "print(confusion_matrix(enc.inverse_transform(y_train),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-tensorflow-py",
   "language": "python",
   "display_name": "Python [conda env:tensorflow] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}